{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from category_encoders import OrdinalEncoder, TargetEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score,classification_report, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pickle\n",
    "import sqlite3\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd(), 'data', '_github-AAC_accidents_tagged_data.xlsx') \n",
    "\n",
    "df = pd.read_excel(DATA_PATH, sheet_name='data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    #Publication Year float to int dtype.\n",
    "    df.dropna(subset=['Publication Year'], inplace=True)\n",
    "    df['Publication Year'] = df['Publication Year'].astype(int)\n",
    "\n",
    "    #Injury level conversion.\n",
    "    # 1: Minor, 2: Serious, 3: Deadly.\n",
    "    df['injury_level'] = [0]*df.shape[0]\n",
    "    injury_level_idx = df.columns.get_loc('injury_level')\n",
    "    df.iloc[np.array(df.loc[:,'Minor'] == 1), injury_level_idx] = 1\n",
    "    df.iloc[np.array(df.loc[:,'Serious'] == 1), injury_level_idx] = 2\n",
    "    df.iloc[np.array(df.loc[:,'Deadly'] == 1), injury_level_idx] = 3\n",
    "    \n",
    "    #Columns to Drop\n",
    "    drop_idx = ['ID', 'Accident Title', 'Text', 'Tags Applied', 'Search Column\\n\\n', \n",
    "        'COUNT OF TAGS', '<15', '15-20', '21-25', '26-30','31-35', '36-50', '51-75', '>75', 'ID',\n",
    "        'Head / Brain Injury', 'Deadly', 'Serious','Minor']\n",
    "    df.drop(drop_idx, axis=1, inplace=True)\n",
    "\n",
    "    #Dropping rows with 'Y' value in month columns.\n",
    "    #Month Columns, Jan-Dec\n",
    "    df.replace('Y', 1, inplace=True)\n",
    "\n",
    "    #Drop dubplicated data rows.\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "    month_cols = ['January','February', 'March', 'April', 'May', 'June', 'July', 'August','September', 'October', 'November', 'December']\n",
    "    exp_cols = ['No/Little', 'Moderate','Experienced', 'Unknown']\n",
    "    climbing_type_cols = ['Descent', 'Roped', 'Trad Climbing', 'Sport',\n",
    "       'Top-Rope', 'Aid & Big Wall Climbing', 'Pendulum', 'Unroped ', 'Solo',\n",
    "       'Climbing Alone', 'Bouldering', 'Non-climbing','Alpine/Mountaineering']\n",
    "    \n",
    "    #Aggregated column for easy sql visualization\n",
    "    modify_dict = {'Month':month_cols, 'Experience':exp_cols, 'Type of Climbing':climbing_type_cols}\n",
    "    for agg in modify_dict.keys():\n",
    "        df[agg] = [0]*df.shape[0]\n",
    "        idx = df.columns.get_loc(agg)\n",
    "        for col_name in modify_dict[agg]:\n",
    "            df.iloc[np.array(df.loc[:,col_name] == 1), idx] = col_name\n",
    "\n",
    "    #Dropping rows with missing values in experience or climbing type columns.\n",
    "    df['Experience'].replace(0, 'Unknown', inplace=True)\n",
    "    df['Type of Climbing'].replace(0, 'Unknown', inplace=True)\n",
    "\n",
    "    #Replacing all NaN with int 0.\n",
    "    df.fillna(0,inplace=True)\n",
    "\n",
    "    df.iloc[:, :-3] = df.iloc[:,:-3].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_clean = process(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_cols = ['January',\n",
    "       'February', 'March', 'April', 'May', 'June', 'July', 'August',\n",
    "       'September', 'October', 'November', 'December']\n",
    "exp_cols = ['No/Little', 'Moderate','Experienced', 'Unknown']\n",
    "climbing_type_cols = ['Descent', 'Roped', 'Trad Climbing', 'Sport',\n",
    "       'Top-Rope', 'Aid & Big Wall Climbing', 'Pendulum', 'Unroped ', 'Solo',\n",
    "       'Climbing Alone', 'Bouldering', 'Non-climbing','Alpine/Mountaineering']\n",
    "alpine_ice_factors_cols = ['Piton/Ice Screw', 'Ascent Illness', 'Crampon Issues', 'Ice Climbing',\n",
    "       'Glissading', 'Ski-related ', 'Poor Position']\n",
    "natural_factors_cols =['Poor Cond/Seasonal Risk', 'Avalanche',\n",
    "       'Cornice / Snow Bridge Collapse', 'Bergschrund',\n",
    "       'Crevasse / Moat / Berschrund', 'Icefall / Serac / Ice Avalanche',\n",
    "       'Exposure', 'Non-Ascent Illness', 'Visibility', 'Severe Weather',\n",
    "       'Wildlife', 'Natural Rockfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = sqlite3.connect('data/AAC_climbing_accidents.db')\n",
    "cursor = cnx.cursor()\n",
    "cursor.execute('DROP TABLE IF EXISTS accident_table')\n",
    "cursor.execute(\"CREATE TABLE accident_table(id INTEGER PRIMARY KEY AUTOINCREMENT)\")\n",
    "\n",
    "cnx.commit() \n",
    "\n",
    "df_clean.to_sql('accident_table', cnx, if_exists='replace', index=False)\n",
    "\n",
    "df_cw = pd.read_sql_query(\"SELECT * FROM accident_table\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['injury_level']\n",
    "drop = [target[0], 'Month', 'Experience', 'Type of Climbing']\n",
    "\n",
    "train, test = train_test_split(df_cw, train_size=0.9, test_size=0.1, random_state=3)\n",
    "train, val = train_test_split(df_cw, train_size=0.80, test_size=0.2, random_state=3)\n",
    "\n",
    "X_train = train.drop(columns=drop)\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=drop)\n",
    "y_val = val[target]\n",
    "X_test = test.drop(columns=drop)\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injury Outcome Counts: \n",
      "2    1771\n",
      "3     561\n",
      "1     219\n",
      "0     190\n",
      "Name: injury_level, dtype: int64\n",
      "\n",
      "Baseline Model Accuracy: 0.6461145567311201\n"
     ]
    }
   ],
   "source": [
    "#Mode class : Serious\n",
    "print(\"Injury Outcome Counts: \")\n",
    "print(df_clean['injury_level'].value_counts())\n",
    "counter = df_clean['injury_level'].value_counts()\n",
    "\n",
    "#Baseline Model Accuracy\n",
    "baseline_accuracy = counter.iloc[0]/counter.sum()\n",
    "print ('\\nBaseline Model Accuracy:' , baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    RandomForestClassifier(random_state=42,\n",
    "                  n_jobs=-1,\n",
    "                  n_estimators=1000,\n",
    "                  max_depth=10,\n",
    "                 )\n",
    ")\n",
    "pipe.fit(X_train, np.ravel(y_train));\n",
    "\n",
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Publication Year    2013\n",
       "No/Little              1\n",
       "Moderate               0\n",
       "Experienced            0\n",
       "Unknown                0\n",
       "                    ... \n",
       "August                 0\n",
       "September              0\n",
       "October                0\n",
       "November               0\n",
       "December               0\n",
       "Name: 1910, Length: 78, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Chanhyung/opt/anaconda3/envs/section3_prj/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(X_test.iloc[0].values.reshape(1,-1))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('section3_prj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "194c0be89ad9b430ae5170d426a51f9b954a7b61f78ec30636c72457aa0369ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
